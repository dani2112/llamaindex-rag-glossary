{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code evaluates the current rag system for correctness. This currently uses the OPENAI API.\n",
    "# rag_eval_local.ipynb contains a locally running vcersion that is unfortunately not yet working due to ragas bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"rag_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = #..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/code/llamaindex-rag-glossary/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 24/24 [00:25<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    context_relevancy,\n",
    ")\n",
    "from ragas import evaluate\n",
    "\n",
    "eval_results = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        answer_correctness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 1.0000, 'answer_relevancy': 0.9416, 'answer_correctness': 0.7314, 'context_precision': 0.2375, 'context_recall': 1.0000, 'context_relevancy': 0.0433}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the similarity map?</td>\n",
       "      <td>A similarity map is a visual representation or...</td>\n",
       "      <td>The Similarity Map is an interactive visualiz...</td>\n",
       "      <td>[---\\ntags: []\\nid: similarity-map\\nsidebar_po...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954392</td>\n",
       "      <td>0.920514</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I install Renumics Spotlight?</td>\n",
       "      <td>You can install Renumics Spotlight by download...</td>\n",
       "      <td>To install Renumics Spotlight, you can use pi...</td>\n",
       "      <td>[---\\nslug: /docs/development\\ntitle: Contribu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978251</td>\n",
       "      <td>0.928695</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want to find duplicates in my data. How can ...</td>\n",
       "      <td>To find duplicates in your data, you can use d...</td>\n",
       "      <td>To find duplicates in your data, you can use ...</td>\n",
       "      <td>[---\\ntags: []\\nid: duplicates-annoy\\nsidebar_...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.898620</td>\n",
       "      <td>0.300865</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.039823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to look at my audio data. Which possibi...</td>\n",
       "      <td>Spotlight offers features like audio visualiza...</td>\n",
       "      <td>Based on the context information provided, Sp...</td>\n",
       "      <td>[`audio(column, window_column=None, name=None,...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.935001</td>\n",
       "      <td>0.775513</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                        What is the similarity map?   \n",
       "1              How can I install Renumics Spotlight?   \n",
       "2  I want to find duplicates in my data. How can ...   \n",
       "3  I want to look at my audio data. Which possibi...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  A similarity map is a visual representation or...   \n",
       "1  You can install Renumics Spotlight by download...   \n",
       "2  To find duplicates in your data, you can use d...   \n",
       "3  Spotlight offers features like audio visualiza...   \n",
       "\n",
       "                                              answer  \\\n",
       "0   The Similarity Map is an interactive visualiz...   \n",
       "1   To install Renumics Spotlight, you can use pi...   \n",
       "2   To find duplicates in your data, you can use ...   \n",
       "3   Based on the context information provided, Sp...   \n",
       "\n",
       "                                            contexts  __index_level_0__  \\\n",
       "0  [---\\ntags: []\\nid: similarity-map\\nsidebar_po...                  0   \n",
       "1  [---\\nslug: /docs/development\\ntitle: Contribu...                  1   \n",
       "2  [---\\ntags: []\\nid: duplicates-annoy\\nsidebar_...                  2   \n",
       "3  [`audio(column, window_column=None, name=None,...                  3   \n",
       "\n",
       "   faithfulness  answer_relevancy  answer_correctness  context_precision  \\\n",
       "0           1.0          0.954392            0.920514               0.75   \n",
       "1           1.0          0.978251            0.928695               0.00   \n",
       "2           NaN          0.898620            0.300865               0.00   \n",
       "3           1.0          0.935001            0.775513               0.20   \n",
       "\n",
       "   context_recall  context_relevancy  \n",
       "0             1.0           0.005714  \n",
       "1             1.0           0.105882  \n",
       "2             1.0           0.039823  \n",
       "3             1.0           0.021739  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_json(\"eval_results.json\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
